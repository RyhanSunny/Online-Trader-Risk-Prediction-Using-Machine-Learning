{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c762b132",
   "metadata": {},
   "source": [
    "# Risk Analysis Project: Predictive Modeling for Online Purchase Order Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448ca32",
   "metadata": {},
   "source": [
    "**Author:** Ryhan Sunny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f82b0d",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f7b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imported libraries here:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e00a54",
   "metadata": {},
   "source": [
    "### Function to Calculate Age from Birthdate\n",
    "This function calculates age from a birthdate string and handles exceptions for invalid or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7eb56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age(birthdate):\n",
    "    try:\n",
    "        birth_date = datetime.strptime(birthdate, '%m/%d/%Y')\n",
    "        current_date = datetime.now()\n",
    "        age = current_date.year - birth_date.year - ((current_date.month, current_date.day) < (birth_date.month, birth_date.day))\n",
    "        return age\n",
    "    except ValueError:\n",
    "        return np.nan  # Return NaN for invalid or missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b52e0b",
   "metadata": {},
   "source": [
    "###  Function to Preprocess Data\n",
    "This function performs data preprocessing, including handling missing values, one-hot encoding for categorical variables, label encoding, age calculation, and other data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c6cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, is_train=True):\n",
    "    # Handle missing values\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    \n",
    "    # One-hot encoding for categorical variables\n",
    "    categorical_columns = [\"Z_METHODE\", \"Z_CARD_ART\", \"Z_LAST_NAME\", \"WEEKDAY_ORDER\"]\n",
    "    df = pd.get_dummies(df, columns=categorical_columns)\n",
    "    \n",
    "    # Replace '?' with NaN and convert 'TIME_ORDER' to minutes past midnight\n",
    "    df['TIME_ORDER'] = df['TIME_ORDER'].replace('?', np.nan)\n",
    "    df['TIME_ORDER'] = pd.to_datetime(df['TIME_ORDER'], errors='coerce').dt.hour * 60 + pd.to_datetime(df['TIME_ORDER'], errors='coerce').dt.minute\n",
    "    mean_time = df['TIME_ORDER'].mean()\n",
    "    df['TIME_ORDER'].fillna(mean_time, inplace=True)\n",
    "    \n",
    "    # Label encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_columns = ['B_EMAIL', 'B_TELEFON', 'FLAG_NEWSLETTER', 'CHK_LADR', 'CHK_RADR', 'CHK_KTO',\n",
    "                       'CHK_CARD', 'CHK_COOKIE', 'CHK_IP', 'FAIL_LPLZ', 'FAIL_LORT', 'FAIL_LPLZORTMATCH',\n",
    "                       'FAIL_RPLZ', 'FAIL_RORT', 'FAIL_RPLZORTMATCH', 'NEUKUNDE', 'FLAG_LRIDENTISCH']\n",
    "    for column in encoded_columns:\n",
    "        df[column] = label_encoder.fit_transform(df[column].astype(str))  # Cast to string to avoid issues with mixed types\n",
    "    \n",
    "    # Convert 'B_BIRTHDATE' to 'AGE' and drop 'B_BIRTHDATE'\n",
    "    df['AGE'] = df['B_BIRTHDATE'].apply(calculate_age)\n",
    "    df.drop(columns=['B_BIRTHDATE'], inplace=True)\n",
    "    \n",
    "    # Replace \"?\" with 0 in specific columns\n",
    "    columns_to_replace_question_mark = [\n",
    "        'ANUMMER_02', 'ANUMMER_03', 'ANUMMER_04', 'ANUMMER_05',\n",
    "        'ANUMMER_06', 'ANUMMER_07', 'ANUMMER_08', 'ANUMMER_09',\n",
    "        'ANUMMER_10', 'DATE_LORDER', 'MAHN_AKT', 'MAHN_HOECHST'\n",
    "    ]\n",
    "    df[columns_to_replace_question_mark] = df[columns_to_replace_question_mark].replace('?', 0)\n",
    "    \n",
    "    # Convert 'DATE_LORDER' to epoch time\n",
    "    df['DATE_LORDER'] = pd.to_datetime(df['DATE_LORDER']).values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "    # Split the data into features and target variable if it's the training data\n",
    "    if is_train:\n",
    "        X = df.drop(\"CLASS\", axis=1)\n",
    "        y = df[\"CLASS\"]\n",
    "        return X, y\n",
    "    else:\n",
    "        X = df.drop(\"CLASS\", axis=1, errors='ignore')  # 'errors' param to ignore if 'CLASS' is not present\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d37c1",
   "metadata": {},
   "source": [
    "### Preprocess the Training Data\n",
    "Reads the training data from a file, preprocesses it using the preprocess_data function, and separates it into features (X) and the target variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8298fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"risk-train.txt\", sep='\\t')\n",
    "X, y = preprocess_data(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189c534",
   "metadata": {},
   "source": [
    "### Split the Data into Training and Validation Sets\n",
    "Splits the data into training and validation sets for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8cc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e52a57",
   "metadata": {},
   "source": [
    " ### Create a Data Processing Pipeline\n",
    " Defines a data processing pipeline that includes scaling and imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57321a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('imputer', SimpleImputer(strategy=\"mean\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78b8ca",
   "metadata": {},
   "source": [
    "### Apply Transformations to Training and Validation Sets\n",
    "Applies transformations, such as scaling and imputation, to both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c68a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_val = pipeline.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a6677",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f750de",
   "metadata": {},
   "source": [
    "### Train the RandomForestClassifier\n",
    "    Initializes and trains a Random Forest Classifier on the preprocessed training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef7f4373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40470748",
   "metadata": {},
   "source": [
    "### Validate the Model\n",
    "Validates the model using the validation set, calculates and prints the confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1632f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5669    0]\n",
      " [ 330    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      1.00      0.97      5669\n",
      "         yes       1.00      0.00      0.01       331\n",
      "\n",
      "    accuracy                           0.94      6000\n",
      "   macro avg       0.97      0.50      0.49      6000\n",
      "weighted avg       0.95      0.94      0.92      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03981b",
   "metadata": {},
   "source": [
    "### Calculate the Accuracy of the Model\n",
    "    Calculates and prints the accuracy of the model on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20f8d567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Validation Data: 94.50%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred == y_val).sum() / len(y_val)\n",
    "print(f\"Model Accuracy on Validation Data: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0e949",
   "metadata": {},
   "source": [
    "### Display the Confusion Matrix\n",
    "    Displays the confusion matrix, which provides insights into the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc40a038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[5669    0]\n",
      " [ 330    1]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31b274",
   "metadata": {},
   "source": [
    "### Print the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d64afbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      1.00      0.97      5669\n",
      "         yes       1.00      0.00      0.01       331\n",
      "\n",
      "    accuracy                           0.94      6000\n",
      "   macro avg       0.97      0.50      0.49      6000\n",
      "weighted avg       0.95      0.94      0.92      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa87ff54",
   "metadata": {},
   "source": [
    "## Cost Calculation and Model Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963aa15a",
   "metadata": {},
   "source": [
    "###  Calculate Misclassification Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "519ed35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassification Cost: 1650\n"
     ]
    }
   ],
   "source": [
    "# Calculate misclassification costs\n",
    "cost_matrix = np.array([[0, 50], [5, 0]])\n",
    "misclassification_cost = 0\n",
    "\n",
    "for true_class, pred_class in zip(y_val, y_pred):\n",
    "    if true_class != pred_class:\n",
    "        if true_class == 'High risk':\n",
    "            misclassification_cost += cost_matrix[0][1]\n",
    "        else:\n",
    "            misclassification_cost += cost_matrix[1][0]\n",
    "\n",
    "print(f\"Total Misclassification Cost: {misclassification_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54e0cdc",
   "metadata": {},
   "source": [
    "###  Save the Model and Pipeline for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7fe5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, \"model.joblib\")\n",
    "joblib.dump(pipeline, \"pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d1476",
   "metadata": {},
   "source": [
    "## Test Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a578ca",
   "metadata": {},
   "source": [
    "### Load and Preprocess the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b2479ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ORDER_ID', 'B_EMAIL', 'B_TELEFON', 'B_BIRTHDATE', 'FLAG_LRIDENTISCH',\n",
      "       'FLAG_NEWSLETTER', 'Z_METHODE', 'Z_CARD_ART', 'Z_CARD_VALID',\n",
      "       'Z_LAST_NAME', 'VALUE_ORDER', 'WEEKDAY_ORDER', 'TIME_ORDER',\n",
      "       'AMOUNT_ORDER', 'ANUMMER_01', 'ANUMMER_02', 'ANUMMER_03', 'ANUMMER_04',\n",
      "       'ANUMMER_05', 'ANUMMER_06', 'ANUMMER_07', 'ANUMMER_08', 'ANUMMER_09',\n",
      "       'ANUMMER_10', 'CHK_LADR', 'CHK_RADR', 'CHK_KTO', 'CHK_CARD',\n",
      "       'CHK_COOKIE', 'CHK_IP', 'FAIL_LPLZ', 'FAIL_LORT', 'FAIL_LPLZORTMATCH',\n",
      "       'FAIL_RPLZ', 'FAIL_RORT', 'FAIL_RPLZORTMATCH', 'SESSION_TIME',\n",
      "       'NEUKUNDE', 'AMOUNT_ORDER_PRE', 'VALUE_ORDER_PRE', 'DATE_LORDER',\n",
      "       'MAHN_AKT', 'MAHN_HOECHST'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"risk-test.txt\", sep='\\t')\n",
    "X_test = preprocess_data(test_data, is_train=False)\n",
    "print(test_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6683b",
   "metadata": {},
   "source": [
    "### Load the Saved Model and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd1b32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_loaded = joblib.load(\"model.joblib\")\n",
    "pipeline_loaded = joblib.load(\"pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba13a60",
   "metadata": {},
   "source": [
    "### Apply Transformations to Test Data and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ca55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pipeline_loaded.transform(X_test)\n",
    "test_predictions = clf_loaded.predict(X_test_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1e81b",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b665710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with 'ORDER-ID' and 'CLASS' columns\n",
    "predictions_df = pd.DataFrame({'ORDER_ID': test_data['ORDER_ID'], 'CLASS': test_predictions})\n",
    "\n",
    "# Convert 'CLASS' values to 'yes' and 'no' based on your classification\n",
    "predictions_df['CLASS'] = np.where(predictions_df['CLASS'] == 'High risk', 'no', 'yes')\n",
    "\n",
    "# Save the predictions to a text file with space separator\n",
    "predictions_df.to_csv(\"test_predictions2.txt\", sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78d019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
